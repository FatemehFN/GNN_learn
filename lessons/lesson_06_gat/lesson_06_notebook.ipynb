{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6: Graph Attention Networks (GAT)\n",
    "\n",
    "This notebook provides hands-on experience with Graph Attention Networks, covering implementation from scratch and practical usage with PyTorch Geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import Cora, Citeseer\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\nprint(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Attention Mechanism\n",
    "\n",
    "Before implementing GAT, let's understand the core attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Attention Weight Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example: Computing attention between a query and multiple keys\n",
    "def compute_scaled_dot_product_attention(Q, K, V, mask=None):\n    \"\"\"\n    Compute scaled dot-product attention.\n    \n    Args:\n        Q: Query (num_queries, d_k)\n        K: Keys (num_keys, d_k)\n        V: Values (num_keys, d_v)\n        mask: Optional mask\n    \n    Returns:\n        attention_output, attention_weights\n    \"\"\"\n    d_k = K.shape[-1]\n    \n    # Compute attention scores\n    scores = torch.matmul(Q, K.T) / np.sqrt(d_k)\n    \n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n    \n    # Softmax to get attention weights\n    attention_weights = F.softmax(scores, dim=-1)\n    \n    # Apply to values\n    attention_output = torch.matmul(attention_weights, V)\n    \n    return attention_output, attention_weights\n\n# Example: 1 query attending to 5 keys\nnp.random.seed(42)\ntorch.manual_seed(42)\n\nd_k = 4\nQ = torch.randn(1, d_k)  # 1 query\nK = torch.randn(5, d_k)  # 5 keys\nV = torch.randn(5, 3)    # 5 values with dimension 3\n\noutput, weights = compute_scaled_dot_product_attention(Q, K, V)\n\nprint(\"Query shape:\", Q.shape)\nprint(\"Keys shape:\", K.shape)\nprint(\"Values shape:\", V.shape)\nprint(\"\\nAttention weights:\", weights)\nprint(\"\\nAttention weights sum:\", weights.sum().item())\nprint(\"\\nOutput shape:\", output.shape)\n\n# Visualize attention weights\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.bar(range(5), weights[0].detach().numpy())\nplt.xlabel('Key Index')\nplt.ylabel('Attention Weight')\nplt.title('Attention Weights Over Keys')\nplt.ylim([0, 1])\n\nplt.subplot(1, 2, 2)\nfor i in range(5):\n    plt.scatter([i] * 3, output[0].detach().numpy(), alpha=0.6, s=100)\nplt.xlabel('Key Index')\nplt.ylabel('Output Dimension')\nplt.title('Aggregated Output')\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing GAT Layer from Scratch\n",
    "\n",
    "Now let's build a single-head GAT layer from scratch to understand the mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Single-Head GAT Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n    \"\"\"\n    Graph Attention Layer - Single Head\n    \n    Computes: h_i' = sigma(sum_j alpha_ij * W * h_j)\n    where alpha_ij = softmax(LeakyReLU(a^T [W*h_i || W*h_j]))\n    \"\"\"\n    \n    def __init__(self, in_features, out_features, dropout=0.0, concat=True):\n        \"\"\"\n        Args:\n            in_features: Input feature dimension\n            out_features: Output feature dimension\n            dropout: Dropout rate for regularization\n            concat: Whether to concatenate features (for intermediate layers)\n        \"\"\"\n        super(GATLayer, self).__init__()\n        \n        self.in_features = in_features\n        self.out_features = out_features\n        self.concat = concat\n        self.dropout = dropout\n        \n        # Linear transformation\n        self.W = nn.Parameter(torch.empty(in_features, out_features))\n        \n        # Attention vector a (requires 2*out_features for concatenated features)\n        self.a = nn.Parameter(torch.empty(2 * out_features, 1))\n        \n        # Bias\n        self.bias = nn.Parameter(torch.empty(out_features))\n        \n        # Initialize parameters\n        self.reset_parameters()\n        \n    def reset_parameters(self):\n        \"\"\"Initialize parameters using Xavier initialization\"\"\"\n        nn.init.xavier_uniform_(self.W)\n        nn.init.xavier_uniform_(self.a)\n        nn.init.zeros_(self.bias)\n    \n    def forward(self, features, edge_index):\n        \"\"\"\n        Args:\n            features: Node features (N, in_features)\n            edge_index: Edge indices (2, E)\n        \n        Returns:\n            output: New node features (N, out_features)\n            attention_weights: Attention coefficients for visualization\n        \"\"\"\n        N = features.shape[0]\n        \n        # Step 1: Linear transformation\n        h = torch.mm(features, self.W)  # (N, out_features)\n        \n        # Step 2: Compute attention logits\n        # For each edge (i,j), we compute a_ij = LeakyReLU(a^T [h_i || h_j])\n        \n        # Get source and target node indices\n        edge_src, edge_dst = edge_index[0], edge_index[1]  # source and destination\n        \n        # Get features for source and destination nodes\n        h_src = h[edge_src]  # (E, out_features)\n        h_dst = h[edge_dst]  # (E, out_features)\n        \n        # Concatenate features: [h_i || h_j]\n        h_concat = torch.cat([h_src, h_dst], dim=1)  # (E, 2*out_features)\n        \n        # Compute attention logits: a^T [h_i || h_j]\n        e = torch.mm(h_concat, self.a).squeeze(-1)  # (E,)\n        \n        # Apply LeakyReLU\n        e = F.leaky_relu(e, negative_slope=0.2)\n        \n        # Step 3: Normalize with softmax\n        # For each node i, normalize over all incoming edges\n        attention = torch.zeros(N, N, device=features.device)\n        attention[edge_src, edge_dst] = e\n        \n        # Softmax per node (per row)\n        attention = F.softmax(attention, dim=1)\n        \n        # Extract non-zero attention weights (only for existing edges)\n        alpha = attention[edge_src, edge_dst]\n        \n        # Step 4: Apply dropout\n        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n        \n        # Step 5: Aggregate features\n        # For each destination node, sum weighted source features\n        output = torch.zeros(N, self.out_features, device=features.device)\n        for i in range(N):\n            # Find edges pointing to node i\n            mask = edge_dst == i\n            if mask.any():\n                weights = alpha[mask]  # attention weights\n                sources = h_src[mask]   # source features\n                # Weighted sum\n                output[i] = torch.sum(weights.unsqueeze(1) * sources, dim=0)\n        \n        # Add bias\n        output = output + self.bias\n        \n        # Apply activation (ReLU for hidden layers, identity for output layer)\n        # (typically applied outside this module)\n        \n        return output, alpha\n    \n    def __repr__(self):\n        return (f'GATLayer(in_features={self.in_features}, '\n                f'out_features={self.out_features})')\n\n\n# Test the implementation\nprint(\"Testing GATLayer implementation...\")\nprint()\n\n# Create a simple graph\nN = 5  # 5 nodes\nF_in = 3  # 3 input features\nF_out = 4  # 4 output features\n\n# Random node features\nfeatures = torch.randn(N, F_in)\n\n# Simple edge list (undirected edges)\nedge_list = [(0, 1), (1, 2), (2, 3), (3, 4), (0, 2), (1, 3), (2, 4), (0, 3)]\nedge_index = torch.tensor(edge_list, dtype=torch.long).T\n\n# Add self-loops\nself_loops = torch.tensor([[i, i] for i in range(N)], dtype=torch.long).T\nedge_index = torch.cat([edge_index, self_loops], dim=1)\n\nprint(f\"Number of nodes: {N}\")\nprint(f\"Number of edges (with self-loops): {edge_index.shape[1]}\")\nprint(f\"Input feature dimension: {F_in}\")\nprint(f\"Output feature dimension: {F_out}\")\nprint()\n\n# Create GAT layer\ngat_layer = GATLayer(F_in, F_out)\n\n# Forward pass\noutput, attention_weights = gat_layer(features, edge_index)\n\nprint(f\"Output shape: {output.shape}\")\nprint(f\"Output:\\n{output}\")\nprint()\nprint(f\"Attention weights shape: {attention_weights.shape}\")\nprint(f\"Attention weights:\\n{attention_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multi-Head GAT Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n    \"\"\"\n    Multi-Head Graph Attention Layer\n    \n    Applies K independent attention heads and concatenates outputs.\n    \"\"\"\n    \n    def __init__(self, in_features, out_features, num_heads=8, dropout=0.0, concat=True):\n        \"\"\"\n        Args:\n            in_features: Input feature dimension\n            out_features: Output feature dimension per head\n            num_heads: Number of attention heads\n            dropout: Dropout rate\n            concat: Whether to concatenate or average heads\n        \"\"\"\n        super(MultiHeadGATLayer, self).__init__()\n        \n        self.in_features = in_features\n        self.out_features = out_features\n        self.num_heads = num_heads\n        self.concat = concat\n        self.dropout = dropout\n        \n        # Create multiple attention heads\n        self.heads = nn.ModuleList([\n            GATLayer(in_features, out_features, dropout=dropout, concat=True)\n            for _ in range(num_heads)\n        ])\n    \n    def forward(self, features, edge_index):\n        \"\"\"\n        Args:\n            features: Node features (N, in_features)\n            edge_index: Edge indices (2, E)\n        \n        Returns:\n            output: New node features (N, num_heads*out_features) or (N, out_features)\n            all_attention: Attention weights from all heads\n        \"\"\"\n        # Apply each head\n        head_outputs = []\n        all_attention = []\n        \n        for head in self.heads:\n            output, attention = head(features, edge_index)\n            head_outputs.append(output)\n            all_attention.append(attention)\n        \n        if self.concat:\n            # Concatenate outputs from all heads\n            output = torch.cat(head_outputs, dim=1)  # (N, num_heads*out_features)\n        else:\n            # Average outputs from all heads\n            output = torch.mean(torch.stack(head_outputs, dim=0), dim=0)  # (N, out_features)\n        \n        return output, all_attention\n    \n    def __repr__(self):\n        return (f'MultiHeadGATLayer(in_features={self.in_features}, '\n                f'out_features={self.out_features}, '\n                f'num_heads={self.num_heads})')\n\n\n# Test multi-head GAT\nprint(\"Testing MultiHeadGATLayer...\")\nprint()\n\nnum_heads = 4\nmulti_head_gat = MultiHeadGATLayer(F_in, F_out, num_heads=num_heads)\n\noutput_multi, attention_multi = multi_head_gat(features, edge_index)\n\nprint(f\"Number of heads: {num_heads}\")\nprint(f\"Output shape (concatenated): {output_multi.shape}\")\nprint(f\"Expected: ({N}, {num_heads * F_out})\")\nprint()\nprint(f\"Number of attention weight tensors: {len(attention_multi)}\")\nfor i, att in enumerate(attention_multi):\n    print(f\"Head {i} attention weights shape: {att.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Complete GAT Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n    \"\"\"\n    Graph Attention Network\n    \n    Multi-layer GAT for node classification.\n    \"\"\"\n    \n    def __init__(self, in_features, hidden_features, out_features, \n                 num_heads=8, num_layers=2, dropout=0.6):\n        \"\"\"\n        Args:\n            in_features: Input feature dimension\n            hidden_features: Hidden feature dimension\n            out_features: Output feature dimension (number of classes)\n            num_heads: Number of attention heads\n            num_layers: Number of GAT layers\n            dropout: Dropout rate\n        \"\"\"\n        super(GAT, self).__init__()\n        \n        self.num_layers = num_layers\n        \n        # First layer\n        self.first_layer = MultiHeadGATLayer(\n            in_features, \n            hidden_features // num_heads,\n            num_heads=num_heads,\n            dropout=dropout,\n            concat=True\n        )\n        \n        # Hidden layers\n        self.hidden_layers = nn.ModuleList([\n            MultiHeadGATLayer(\n                hidden_features,\n                hidden_features // num_heads,\n                num_heads=num_heads,\n                dropout=dropout,\n                concat=True\n            )\n            for _ in range(num_layers - 2)\n        ])\n        \n        # Output layer (typically using averaging instead of concatenation)\n        self.output_layer = MultiHeadGATLayer(\n            hidden_features,\n            out_features,\n            num_heads=num_heads,\n            dropout=dropout,\n            concat=False  # Average instead of concatenate\n        )\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, features, edge_index):\n        \"\"\"\n        Args:\n            features: Node features (N, in_features)\n            edge_index: Edge indices (2, E)\n        \n        Returns:\n            output: Logits (N, out_features)\n        \"\"\"\n        # First layer\n        x, _ = self.first_layer(features, edge_index)\n        x = F.elu(x)\n        x = self.dropout(x)\n        \n        # Hidden layers\n        for layer in self.hidden_layers:\n            x, _ = layer(x, edge_index)\n            x = F.elu(x)\n            x = self.dropout(x)\n        \n        # Output layer\n        x, _ = self.output_layer(x, edge_index)\n        \n        return x\n\n\n# Test complete GAT\nprint(\"Testing complete GAT network...\")\nprint()\n\nmodel = GAT(\n    in_features=F_in,\n    hidden_features=16,\n    out_features=4,  # 4 classes\n    num_heads=4,\n    num_layers=2,\n    dropout=0.5\n)\n\noutput = model(features, edge_index)\nprint(f\"Model output shape: {output.shape}\")\nprint(f\"Expected: ({N}, 4)\")\nprint()\nprint(f\"Model:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using PyTorch Geometric's GATConv\n",
    "\n",
    "Now let's use the optimized implementation from PyTorch Geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cora dataset\nprint(\"Loading Cora dataset...\")\ndataset = Cora(root='/tmp/Cora')\ndata = dataset[0]\n\nprint(f\"Dataset: {dataset}\")\nprint(f\"Number of nodes: {data.num_nodes}\")\nprint(f\"Number of edges: {data.num_edges}\")\nprint(f\"Number of node features: {data.num_node_features}\")\nprint(f\"Number of classes: {dataset.num_classes}\")\nprint(f\"Train nodes: {data.train_mask.sum().item()}\")\nprint(f\"Val nodes: {data.val_mask.sum().item()}\")\nprint(f\"Test nodes: {data.test_mask.sum().item()}\")\nprint()\nprint(f\"Data: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build GAT Model with PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n    \"\"\"\n    GAT model using PyTorch Geometric's GATConv.\n    \"\"\"\n    \n    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=8, dropout=0.6):\n        super(GATModel, self).__init__()\n        \n        self.gat1 = GATConv(in_channels, hidden_channels, heads=num_heads, dropout=dropout)\n        self.gat2 = GATConv(hidden_channels * num_heads, out_channels, heads=1, dropout=dropout)\n        self.dropout = dropout\n    \n    def forward(self, x, edge_index):\n        x = self.gat1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.gat2(x, edge_index)\n        return x\n\n\n# Create model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GATModel(\n    in_channels=data.num_node_features,\n    hidden_channels=8,\n    out_channels=dataset.num_classes,\n    num_heads=8,\n    dropout=0.6\n).to(device)\n\nprint(f\"Model:\\n{model}\")\nprint()\nprint(f\"Device: {device}\")\nprint(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, device, epochs=100):\n    \"\"\"\n    Train the GAT model.\n    \"\"\"\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n    \n    data = data.to(device)\n    train_losses = []\n    val_accs = []\n    \n    for epoch in range(epochs):\n        model.train()\n        optimizer.zero_grad()\n        \n        out = model(data.x, data.edge_index)\n        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        \n        # Validation\n        model.eval()\n        with torch.no_grad():\n            out = model(data.x, data.edge_index)\n            pred = out.argmax(dim=1)\n            val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n            val_accs.append(val_acc)\n        \n        if (epoch + 1) % 20 == 0:\n            print(f\"Epoch {epoch+1:3d} | Loss: {loss:.4f} | Val Acc: {val_acc:.4f}\")\n    \n    return train_losses, val_accs\n\n\nprint(\"Training GAT model...\")\ntrain_losses, val_accs = train(model, data, device, epochs=200)\nprint(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Evaluate on Test Set"
   ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, device):\n    \"\"\"\n    Evaluate the model on test set.\n    \"\"\"\n    model.eval()\n    data = data.to(device)\n    \n    with torch.no_grad():\n        out = model(data.x, data.edge_index)\n        pred = out.argmax(dim=1)\n        \n        train_acc = (pred[data.train_mask] == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n        val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n        test_acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n    \n    return train_acc, val_acc, test_acc\n\n\ntrain_acc, val_acc, test_acc = evaluate(model, data, device)\n\nprint(f\"Final Results:\")\nprint(f\"Train Accuracy: {train_acc:.4f}\")\nprint(f\"Val Accuracy:   {val_acc:.4f}\")\nprint(f\"Test Accuracy:  {test_acc:.4f}\")\nprint()\n\n# Plot training curves\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\naxes[0].plot(train_losses)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Training Loss')\naxes[0].set_title('Training Loss Over Time')\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(val_accs)\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Validation Accuracy')\naxes[1].set_title('Validation Accuracy Over Time')\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing Attention Weights\n",
    "\n",
    "One of the key advantages of GAT is interpretability through attention visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Extract Attention Weights from PyG GATConv"
   ]
  },
  {
   "function_calls": [
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
    "class GATModelWithAttention(nn.Module):\n    \"\"\"\n    GAT model that returns attention weights for visualization.\n    \"\"\"\n    \n    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=8, dropout=0.6):\n        super(GATModelWithAttention, self).__init__()\n        \n        self.gat1 = GATConv(in_channels, hidden_channels, heads=num_heads, dropout=dropout)\n        self.gat2 = GATConv(hidden_channels * num_heads, out_channels, heads=1, dropout=dropout)\n        self.dropout = dropout\n    \n    def forward(self, x, edge_index, return_attention=False):\n        x = self.gat1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        \n        if return_attention:\n            x, (edge_index_out, attention) = self.gat2(x, edge_index, return_attention_weights=True)\n            return x, attention\n        else:\n            x = self.gat2(x, edge_index)\n            return x\n\n\n# Load pre-trained model and extract attention\nmodel_att = GATModelWithAttention(\n    in_channels=data.num_node_features,\n    hidden_channels=8,\n    out_channels=dataset.num_classes,\n    num_heads=8,\n    dropout=0.6\n).to(device)\n\n# Copy weights from trained model\nmodel_att.load_state_dict(model.state_dict())\n\nmodel_att.eval()\nwith torch.no_grad():\n    out, attention = model_att(data.x.to(device), data.edge_index.to(device), return_attention=True)\n    print(f\"Attention weights shape: {attention.shape}\")\n    print(f\"Attention min: {attention.min().item():.6f}\")\n    print(f\"Attention max: {attention.max().item():.6f}\")\n    print(f\"Attention mean: {attention.mean().item():.6f}\")"
   ]
   }
  ],
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualize Attention Weights for Sample Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few test nodes\ntest_nodes = data.test_mask.nonzero(as_tuple=True)[0][:5]\n\nfig, axes = plt.subplots(1, len(test_nodes), figsize=(15, 3))\n\nfor idx, node_id in enumerate(test_nodes):\n    # Find edges involving this node\n    incoming = data.edge_index[1] == node_id\n    edge_src = data.edge_index[0][incoming]\n    edge_att = attention[incoming].cpu().numpy()\n    \n    axes[idx].barh(range(len(edge_src)), edge_att)\n    axes[idx].set_xlabel('Attention Weight')\n    axes[idx].set_title(f'Node {node_id.item()} Attention')\n    axes[idx].set_ylim([-1, len(edge_src)])\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Visualized attention weights for {len(test_nodes)} test nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Attention Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# Histogram of attention weights\naxes[0, 0].hist(attention.cpu().detach().numpy(), bins=50, edgecolor='black')\naxes[0, 0].set_xlabel('Attention Weight')\naxes[0, 0].set_ylabel('Frequency')\naxes[0, 0].set_title('Distribution of Attention Weights')\n\n# Box plot\naxes[0, 1].boxplot(attention.cpu().detach().numpy())\naxes[0, 1].set_ylabel('Attention Weight')\naxes[0, 1].set_title('Attention Weights Box Plot')\n\n# CDF of attention weights\nsorted_att = torch.sort(attention.flatten())[0].cpu().numpy()\naxes[1, 0].plot(sorted_att, np.arange(len(sorted_att)) / len(sorted_att))\naxes[1, 0].set_xlabel('Attention Weight')\naxes[1, 0].set_ylabel('Cumulative Probability')\naxes[1, 0].set_title('CDF of Attention Weights')\naxes[1, 0].grid(True, alpha=0.3)\n\n# Top-K attention weights\ntop_k = 20\ntop_att = torch.topk(attention.flatten(), top_k)[0].cpu().numpy()\naxes[1, 1].bar(range(top_k), top_att)\naxes[1, 1].set_xlabel('Rank')\naxes[1, 1].set_ylabel('Attention Weight')\naxes[1, 1].set_title(f'Top {top_k} Attention Weights')\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Comparing GAT vs GCN\n",
    "\n",
    "Let's compare the performance and characteristics of GAT and GCN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Build and Train GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n    \"\"\"\n    GCN model for comparison.\n    \"\"\"\n    \n    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.6):\n        super(GCNModel, self).__init__()\n        \n        self.gcn1 = GCNConv(in_channels, hidden_channels)\n        self.gcn2 = GCNConv(hidden_channels, out_channels)\n        self.dropout = dropout\n    \n    def forward(self, x, edge_index):\n        x = self.gcn1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.gcn2(x, edge_index)\n        return x\n\n\ndef train_and_evaluate(model, data, device, epochs=200, model_name='Model'):\n    \"\"\"\n    Train and evaluate a model.\n    \"\"\"\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n    data = data.to(device)\n    \n    train_losses = []\n    val_accs = []\n    test_accs = []\n    \n    print(f\"Training {model_name}...\")\n    \n    for epoch in range(epochs):\n        model.train()\n        optimizer.zero_grad()\n        \n        out = model(data.x, data.edge_index)\n        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        \n        # Validation and test\n        model.eval()\n        with torch.no_grad():\n            out = model(data.x, data.edge_index)\n            pred = out.argmax(dim=1)\n            \n            val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n            test_acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n            \n            val_accs.append(val_acc)\n            test_accs.append(test_acc)\n        \n        if (epoch + 1) % 50 == 0:\n            print(f\"Epoch {epoch+1:3d} | Loss: {loss:.4f} | Val Acc: {val_acc:.4f} | Test Acc: {test_acc:.4f}\")\n    \n    print(f\"Training {model_name} completed!\\n\")\n    return train_losses, val_accs, test_accs\n\n\n# Create and train GCN\ngcn_model = GCNModel(\n    in_channels=data.num_node_features,\n    hidden_channels=8,\n    out_channels=dataset.num_classes,\n    dropout=0.6\n).to(device)\n\ngcn_train_losses, gcn_val_accs, gcn_test_accs = train_and_evaluate(\n    gcn_model, data, device, epochs=200, model_name='GCN'\n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final accuracies\ngat_train_acc, gat_val_acc, gat_test_acc = evaluate(model, data, device)\ngcn_train_acc, gcn_val_acc, gcn_test_acc = evaluate(gcn_model, data, device)\n\nprint(\"=\"*60)\nprint(\"COMPARISON: GAT vs GCN\")\nprint(\"=\"*60)\nprint()\nprint(f\"{'Metric':<20} {'GAT':<15} {'GCN':<15} {'Difference':<15}\")\nprint(\"-\" * 60)\nprint(f\"{'Train Accuracy':<20} {gat_train_acc:.4f}{'':<10} {gcn_train_acc:.4f}{'':<10} {gat_train_acc-gcn_train_acc:+.4f}\")\nprint(f\"{'Val Accuracy':<20} {gat_val_acc:.4f}{'':<10} {gcn_val_acc:.4f}{'':<10} {gat_val_acc-gcn_val_acc:+.4f}\")\nprint(f\"{'Test Accuracy':<20} {gat_test_acc:.4f}{'':<10} {gcn_test_acc:.4f}{'':<10} {gat_test_acc-gcn_test_acc:+.4f}\")\nprint()\n\n# Plot comparison\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Training loss\naxes[0].plot(train_losses, label='GAT', linewidth=2)\naxes[0].plot(gcn_train_losses, label='GCN', linewidth=2)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Training Loss')\naxes[0].set_title('Training Loss Comparison')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Validation accuracy\naxes[1].plot(val_accs, label='GAT', linewidth=2)\naxes[1].plot(gcn_val_accs, label='GCN', linewidth=2)\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Validation Accuracy')\naxes[1].set_title('Validation Accuracy Comparison')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\n# Test accuracy\naxes[2].plot(test_accs, label='GAT', linewidth=2)\naxes[2].plot(gcn_test_accs, label='GCN', linewidth=2)\naxes[2].set_xlabel('Epoch')\naxes[2].set_ylabel('Test Accuracy')\naxes[2].set_title('Test Accuracy Comparison')\naxes[2].legend()\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model Complexity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters\ngat_params = sum(p.numel() for p in model.parameters())\ngcn_params = sum(p.numel() for p in gcn_model.parameters())\n\nprint(\"Model Complexity Comparison:\")\nprint(\"=\"*50)\nprint(f\"GAT Parameters:  {gat_params:,}\")\nprint(f\"GCN Parameters:  {gcn_params:,}\")\nprint(f\"Ratio (GAT/GCN): {gat_params/gcn_params:.2f}x\")\nprint()\n\n# Time complexity analysis\nprint(\"Time Complexity:\")\nprint(\"=\"*50)\nprint(f\"Both have O(N*F*F') for feature transformation\")\nprint(f\"Both have O(E*F') for message passing\")\nprint(f\"GAT has additional O(E*log(D)) for attention softmax\")\nprint(f\"where N={data.num_nodes}, E={data.num_edges}, F=in_features, F'=hidden_features, D=avg_degree\")\nprint()\nprint(f\"Graph density: {2*data.num_edges/(data.num_nodes**2):.4f}\")\nprint(f\"Average degree: {2*data.num_edges/data.num_nodes:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Interpreting Learned Attention\n",
    "\n",
    "Understanding what the model learned through attention patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Analyzing Attention Patterns"
   ]
  },
  {
   "cell_type": {"text/markdown"}: [
    "### 6.2 Correlation Between Attention and Feature Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature similarity for all edges\ndata_cpu = data.cpu()\nfeatures = data_cpu.x.cpu().numpy()\nedge_index = data_cpu.edge_index.cpu().numpy()\nattention_weights = attention.cpu().detach().numpy()\n\n# Compute cosine similarity for each edge\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nsimilarities = []\nfor i, (src, dst) in enumerate(edge_index.T):\n    src_feat = features[src].reshape(1, -1)\n    dst_feat = features[dst].reshape(1, -1)\n    sim = cosine_similarity(src_feat, dst_feat)[0, 0]\n    similarities.append(sim)\n\nsimilarities = np.array(similarities)\n\n# Plot correlation\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Scatter plot\naxes[0].scatter(similarities, attention_weights, alpha=0.3, s=10)\naxes[0].set_xlabel('Feature Similarity')\naxes[0].set_ylabel('Attention Weight')\naxes[0].set_title('Feature Similarity vs Attention Weight')\naxes[0].grid(True, alpha=0.3)\n\n# Calculate correlation\ncorr = np.corrcoef(similarities, attention_weights)[0, 1]\naxes[0].text(0.05, 0.95, f'Correlation: {corr:.4f}', \n             transform=axes[0].transAxes, fontsize=12, verticalalignment='top',\n             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# 2D histogram\naxes[1].hist2d(similarities, attention_weights, bins=50)\naxes[1].set_xlabel('Feature Similarity')\naxes[1].set_ylabel('Attention Weight')\naxes[1].set_title('2D Histogram: Feature Similarity vs Attention')\nplt.colorbar(axes[1].collections[0], ax=axes[1])\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Correlation between feature similarity and attention: {corr:.4f}\")\nprint(f\"This indicates that attention weights {'ARE' if abs(corr) > 0.3 else 'are NOT'} strongly correlated with feature similarity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Attention Patterns by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attention patterns for different node classes\nclasses = data.y.unique().cpu().numpy()\nclass_attention = {c: [] for c in classes}\n\nfor i, (src, dst) in enumerate(edge_index.T):\n    src_class = data.y[src].item()\n    class_attention[src_class].append(attention_weights[i])\n\n# Create violin plot\nfig, ax = plt.subplots(figsize=(10, 5))\n\ndata_to_plot = [class_attention[c] for c in sorted(classes)]\nax.violinplot(data_to_plot, positions=sorted(classes), showmeans=True, showmedians=True)\nax.set_xlabel('Source Node Class')\nax.set_ylabel('Attention Weight Distribution')\nax.set_title('Attention Weight Distribution by Source Node Class')\nax.set_xticks(sorted(classes))\nax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nAttention statistics by source node class:\")\nprint(\"=\"*60)\nfor c in sorted(classes):\n    att = np.array(class_attention[c])\n    print(f\"Class {c}: mean={att.mean():.4f}, std={att.std():.4f}, min={att.min():.4f}, max={att.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Exercises\n",
    "\n",
    "Practice problems to deepen understanding of GAT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement Attention Head Ablation\n",
    "\n",
    "Build a model that uses varying numbers of attention heads (1, 2, 4, 8, 16) and compare their performance.\n",
    "\n",
    "**TODO**: Complete the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Head Ablation Study\n",
    "head_counts = [1, 2, 4, 8, 16]\nhead_results = {}\n",
    "\n# TODO: For each head count:\n# 1. Create a GATModel with that number of heads\n# 2. Train it on the Cora dataset\n# 3. Record the final test accuracy\n# 4. Store in head_results[head_count] = (test_acc, num_params)\n\n# Hint: Use the train_and_evaluate function defined above\n\n# Solution template:\nprint(\"Exercise 1: Attention Head Ablation Study\")\nprint(\"=\"*50)\nprint()\nprint(\"TODO: Implement head ablation study\")\nprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Dropout and Regularization\n",
    "\n",
    "Investigate how dropout affects attention weight distributions and model generalization.\n",
    "\n",
    "**TODO**: Complete the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Dropout Analysis\n\n# TODO: \n# 1. Train GAT models with different dropout rates: [0.0, 0.3, 0.6, 0.9]\n# 2. For each, record train, val, and test accuracy\n# 3. Visualize how dropout affects overfitting\n# 4. Analyze attention weight distributions at different dropout rates\n\nprint(\"Exercise 2: Dropout and Regularization Analysis\")\nprint(\"=\"*50)\nprint()\nprint(\"TODO: Implement dropout analysis\")\nprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Edge Weight Interpretation\n",
    "\n",
    "For misclassified nodes, analyze which edges received high attention.\n",
    "\n",
    "**TODO**: Complete the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Edge Weight Interpretation for Misclassified Nodes\n\n# TODO:\n# 1. Identify misclassified nodes in the test set\n# 2. For each misclassified node, find the edges with highest attention\n# 3. Analyze whether high-attention edges point to correct class nodes\n# 4. Create visualization showing attention patterns for misclassified nodes\n\nprint(\"Exercise 3: Edge Weight Interpretation\")\nprint(\"=\"*50)\nprint()\nprint(\"TODO: Analyze attention patterns for misclassified nodes\")\nprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Graph Structure Comparison\n",
    "\n",
    "Compare GAT performance on different datasets (Cora, Citeseer).\n",
    "\n",
    "**TODO**: Complete the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Cross-Dataset Comparison\n",
    "\n",
    "# TODO:\n    # 1. Load Citeseer dataset\n    # 2. Train GAT and GCN on Citeseer\n    # 3. Compare results with Cora\n    # 4. Analyze graph properties (density, clustering coefficient, etc.)\n    # 5. Discuss why GAT/GCN may perform differently on different graphs\n\n    print(\"Exercise 4: Graph Structure Comparison\")\n    print(\"=\"*50)\n    print()\n    print(\"TODO: Compare GAT performance across different datasets\")\n    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Attention-based Feature Analysis\n",
    "\n",
    "Use attention weights to identify important node features.\n",
    "\n",
    "**TODO**: Complete the code below"
   ]
  },
  {
   "cell_type": {"text/markdown"}: [
    "### Exercise 5: Attention-based Feature Importance\n",
    "\n",
    "Create a method to identify which features contribute most to high attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Feature Importance via Attention\n",
    "\n",
    "# TODO:\n    # 1. For edges with high attention weights, analyze source/target features\n    # 2. Identify which features correlate with high attention\n    # 3. Create a feature importance ranking\n    # 4. Compare with statistical feature importance (e.g., variance, mutual information)\n\n    print(\"Exercise 5: Attention-based Feature Importance\")\n    print(\"=\"*50)\n    print()\n    print(\"TODO: Identify important features through attention analysis\")\n    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, you've learned:\n",
    "\n",
    "1. **Attention Mechanism Basics**\n",
    "   - How queries, keys, and values work\n",
    "   - Scaled dot-product attention\n",
    "   - Softmax normalization\n",
    "\n",
    "2. **GAT Implementation**\n",
    "   - Building GAT layers from scratch\n",
    "   - Multi-head attention\n",
    "   - Complete GAT networks\n",
    "\n",
    "3. **Using PyTorch Geometric**\n",
    "   - GATConv layer\n",
    "   - Training and evaluation\n",
    "   - Extracting attention weights\n",
    "\n",
    "4. **Attention Visualization**\n",
    "   - Visualizing attention weights\n",
    "   - Analyzing attention distributions\n",
    "   - Interpreting learned patterns\n",
    "\n",
    "5. **GAT vs GCN Comparison**\n",
    "   - Performance differences\n",
    "   - Computational complexity\n",
    "   - Advantages and trade-offs\n",
    "\n",
    "6. **Interpretation and Analysis**\n",
    "   - Attention-based explanations\n",
    "   - Feature similarity correlation\n",
    "   - Class-specific patterns\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- GAT learns task-specific attention weights for each edge\n",
    "- Attention mechanisms enable interpretability\n",
    "- Multi-head attention captures diverse relationships\n",
    "- GAT often outperforms GCN on heterogeneous graphs\n",
    "- Attention weights can reveal important graph structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
